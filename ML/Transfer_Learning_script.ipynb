{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TH_AI_Transfer Learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjU99OpdGnqO"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.layers import BatchNormalization, Dropout\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_P95gZhGtAJ"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh4gI-zsGuV4",
        "outputId": "005e1a76-494d-48e7-873d-40517bf3b556"
      },
      "source": [
        "print(\"Train Images Shape : \" + str(train_images.shape))\n",
        "print(\"Test Images Shape : \" + str(test_images.shape))\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Images Shape : (50000, 32, 32, 3)\n",
            "Test Images Shape : (10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXGbbfVyGvnY"
      },
      "source": [
        "# The classes in CIFAR-10 dataset\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SJk5zb3Gw7x"
      },
      "source": [
        "vgg19 = VGG19(weights=\"imagenet\", include_top=False, input_shape=(32,32, 3))\n",
        "vgg19.trainable = False"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lK28vjUVHREB",
        "outputId": "8b7a511e-00ab-4fd2-c370-3b8af001a606"
      },
      "source": [
        "x = vgg19.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Dropout(0.5)(x) \n",
        "x = Dense(512, activation ='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(10, activation ='softmax')(x)\n",
        "\n",
        "\n",
        "model = Model(vgg19.input, x)\n",
        "model.compile(optimizer ='Adam', \n",
        "              loss =\"sparse_categorical_crossentropy\", \n",
        "              metrics =[\"sparse_categorical_accuracy\"]) \n",
        "\n",
        "history = model.fit(train_images,train_labels, epochs = 5, validation_data = (test_images,test_labels), verbose = 1, shuffle=True)\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 827s 529ms/step - loss: 1.8048 - sparse_categorical_accuracy: 0.4023 - val_loss: 1.3744 - val_sparse_categorical_accuracy: 0.5200\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 810s 518ms/step - loss: 1.5588 - sparse_categorical_accuracy: 0.4482 - val_loss: 1.3261 - val_sparse_categorical_accuracy: 0.5284\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 824s 527ms/step - loss: 1.5261 - sparse_categorical_accuracy: 0.4638 - val_loss: 1.3064 - val_sparse_categorical_accuracy: 0.5354\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 826s 529ms/step - loss: 1.4984 - sparse_categorical_accuracy: 0.4711 - val_loss: 1.2900 - val_sparse_categorical_accuracy: 0.5459\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 823s 527ms/step - loss: 1.4849 - sparse_categorical_accuracy: 0.4752 - val_loss: 1.2758 - val_sparse_categorical_accuracy: 0.5546\n",
            "313/313 [==============================] - 137s 439ms/step - loss: 1.2758 - sparse_categorical_accuracy: 0.5546\n",
            "Test accuracy: 0.5546000003814697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuRCZWTQHnDI"
      },
      "source": [
        "model.save('transfer_model.h5')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm9YnWUDJwvj"
      },
      "source": [
        "\"\"\"\n",
        "Run this cell, by replacing \"<IMAGE_PATH_HERE>\" with your image path to test a custom image\n",
        "\"\"\"\n",
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "new_model = tf.keras.models.load_model('transfer_model.h5')\n",
        "\n",
        "def test(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (32, 32))\n",
        "    img = img / 255.0\n",
        "    res = model.predict(np.array([img]))\n",
        "    ans = np.argmax(res)\n",
        "    print(class_names[ans])\n",
        "\n",
        "test(\"<IMAGE_PATH_HERE>\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}